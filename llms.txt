# Templates Repository

> Collection of reusable templates for client documentation, llms.txt creation, and ML operations runbooks.

## Project Overview

**Tech Stack**: Markdown templates
**Status**: Production-ready collection
**Purpose**: Provides standardized templates for client communication, AI-assisted development workflows, and machine learning operations documentation

---

## Core Documentation

### README.md
Comprehensive repository overview and usage guide. Read this file to understand what's inside this templates repository (Cursor AI rules, reusable prompts, project templates), how to use each type of template, quick start instructions for new and existing projects, the philosophy behind AI-native development, and how these templates improve AI performance. Use this file when first discovering the repository, determining which templates to adopt, or explaining the repository to team members. Includes sections on what's inside (three template categories), quick start for new projects (copy rules, templates, fill placeholders), quick start for existing projects (adopt incrementally), additional resources (client docs, llms.txt framework, ML runbooks), philosophy explanation (AI-native vs traditional documentation), benefits (reduces hallucinations, maintains consistency, speeds onboarding), maintenance guidance, and credits. Essential first read for anyone using these templates.

### QUICK_START.md
Fast-reference guide for copying templates into projects. Read this file to understand the four-step process for new projects (copy Cursor rules, copy project templates, fill placeholders, use prompts during development) and quick-start approach for existing projects. Use this file when setting up a new project and need simple copy-paste commands without extensive explanation. Includes bash commands for copying files, explanations of what each template folder does, example workflow showing full process from mkdir to first commit, and tips for staying current. Points to EXISTING_PROJECT_GUIDE.md for projects without existing architecture docs. Designed for speed over depth - see README.md for comprehensive context.

### EXISTING_PROJECT_GUIDE.md
Step-by-step guide for adopting templates in established codebases without existing documentation. Read this file to understand the six-phase adoption approach (add Cursor rules → create memory.md → create architecture.md → create decisions.md → create llms.txt → optional templates), how to document current state when you don't have architecture.md or memory.md, mining git history for decisions and milestones, using AI to help document existing architecture, prioritizing which templates to add first, and realistic time estimates per phase. Use this file when adding templates to projects with established code but no structured docs, feeling overwhelmed about where to start documenting, need to bootstrap architecture.md from existing system, or want week-by-week migration checklist. Includes concrete examples of what to write in each template (memory.md with 3-5 milestones, architecture.md with system overview, decisions.md with major technical choices), git commands for mining history, AI-assisted documentation prompts, maintenance strategy (weekly/monthly/quarterly), common pitfalls to avoid (don't document what you wish you had, document what exists), quick migration checklist (Day 1 = 1 hour, Week 1 = 3-4 hours), team buy-in strategies, and real migration example showing 2x faster onboarding. Critical resource for existing codebases lacking documentation.

### PROMPT_PLAYBOOK.md
Comprehensive index and guide for all prompts with usage patterns. Read this file to understand all available prompts organized by category (general AI prompts vs Cursor coding prompts), what each prompt does with brief description, quick reference workflows (first time in codebase, starting feature, investigating bug, before submitting work), advanced patterns like prompt chaining and multi-step workflows, and pro tips for grounding AI in project context. Use this file when need to find the right prompt for a task, want to understand prompt chaining strategies, learning available prompts, or need detailed usage patterns with examples. Includes sections for general AI prompts (11 prompts for any AI assistant including TCREI template, prompt engineer, rage mode, systems architect, startup cofounder, learning accelerator, code explainer, self-critique, research synthesizer, speed summary, master framework), Cursor development prompts (11 prompts specific to coding including understand-codebase, repository-map, task-splitter, follow-project-rules, update-memory, plus original planning/debugging/feature-dev/testing/refactoring/pr-writing), quick reference tables, advanced prompt chaining examples, and pro tips for iterative improvement. See PROMPT_CHEATSHEET.md for ultra-concise lookup.

### PROMPT_CHEATSHEET.md
One-page lookup table for quick prompt reference. Read this file to rapidly find what each prompt does without reading detailed explanations. Use this file when you see a prompt filename like "rage-mode" and need to quickly understand what it does, need fast lookup during active work, or want printable one-page reference. Includes three tables: general AI prompts table (name and one-sentence description), Cursor coding prompts table (name and one-sentence description), and quick workflows (new codebase, new feature, bug, refactor). Each entry is ultra-concise (under 15 words). Points to PROMPT_PLAYBOOK.md for detailed usage. Designed for speed - scan the table, find your prompt, use it.

---

## Client Documentation Templates

### client-docs/MONTHLY_REPORT.template.md
Comprehensive monthly development report template for retainer clients. Read this file to understand how to structure detailed monthly reports including hours breakdown, work completed, system health metrics, infrastructure costs, support tickets, security updates, upcoming work, recommendations, and client action items. Use this template when preparing monthly status reports for retainer-based development partnerships. Includes sections for time allocation tables, detailed time logs, work categorization (bug fixes, enhancements, new features, security), performance metrics, database statistics, cost tracking, and risk assessment. Essential for maintaining transparent client relationships and demonstrating value delivered. Designed for consultants and agencies on monthly retainer agreements tracking 20-40+ hours of work per month.

### client-docs/RETAINER_AGREEMENT.template.md
Complete retainer agreement template for development partnership contracts. Read this file to understand how to structure long-term development retainer agreements including scope of services, SLA definitions, hours management, payment terms, and deliverables. Use this template when establishing or formalizing ongoing development partnerships with clients. Includes sections for duration and auto-renewal terms, monthly investment structure, response time SLAs by priority level (Critical/High/Medium/Low), hours rollover policies, out-of-scope definitions, technology stack coverage, quarterly planning frameworks, value proposition comparisons, intellectual property terms, confidentiality clauses, and termination conditions. Covers both technical partnership aspects (proactive monitoring, strategic consultation) and business terms (billing, liability, insurance). Designed to replace project-by-project contracts with predictable recurring revenue relationships.

### client-docs/RETAINER_VALUE_ANALYSIS.template.md
Financial and strategic analysis template for positioning retainer agreements. Read this file to understand how to calculate, present, and justify retainer pricing from both consultant and client perspectives including revenue comparison scenarios, effective hourly rates, risk mitigation strategies, and ROI demonstrations. Use this template when preparing to pitch a retainer agreement to a client, analyzing whether a retainer makes financial sense, or positioning the value proposition. Includes detailed math breakdowns comparing retainer vs project-based revenue models, cost comparison tables (retainer vs part-time hire vs agency vs full-time), client value proposition frameworks, efficiency gains analysis, time breakdown calculations, effective rate scenarios (conservative/average/high usage), risk mitigation strategies for both parties, objection handling responses ("seems too expensive", "what if no work", "can I cancel"), success metrics definitions, and positioning conversation scripts. Particularly valuable for freelancers and agencies transitioning from project work to recurring revenue models. Shows how to frame a $3-8K/month retainer as cost savings for clients while providing revenue stability for consultants.

---

## llms.txt Creation Framework

### llms-txt/LLM_TXT_STANDARDS.md
Research-backed best practices and standards for creating optimized llms.txt files that maximize AI code agent performance. Read this file to understand why optimized llms.txt files outperform vector databases (95% vs 85% success rate), how to write effective file descriptions, proper structure and formatting rules, and quality optimization checklists. Use this file when creating new llms.txt files, optimizing existing ones, or teaching others about effective AI-assisted development workflows. Includes the file description template format (opening statement + primary concepts + use cases + specific functions + dependencies), structure guidelines for project overview and functional area organization, reasoning-friendly language patterns (verb-based descriptions starting with "Read this file to...", "Reference this for...", "Use when..."), anti-patterns to avoid (generic descriptions, missing context, listings without explanation), size guidelines (5,000-20,000 tokens optimal), maintenance triggers (when to update), and real-world examples of well-optimized vs poorly-optimized entries. Based on empirical research by Lance Martin showing clear descriptions enable better retrieval decisions. Critical reference for anyone implementing llms.txt in their projects. Explains why "RAG with full documents as retrieval units" outperforms context stuffing and standard documentation approaches.

### llms-txt/CREATE_LLM_TXT.md
Simple instruction guide for AI assistants to create llms.txt files using LLM_TXT_STANDARDS.md. Read this file to understand the quick commands and workflows for generating optimized llms.txt files automatically. Use this file when you want to quickly create or update an llms.txt file by providing it to an AI assistant along with the standards document. Includes three main usage patterns: full auto-generation (scan all files and create from scratch), update existing llms.txt (optimize current file), and add specific files (update with new additions). Provides copy-paste commands, expected output structure preview, tips for best results, and recommendations for file placement (shared templates in central location vs copied to each project). Designed to minimize friction in llms.txt adoption by reducing the task to a single command. References LLM_TXT_STANDARDS.md as the source of truth. Useful for teams implementing llms.txt workflows across multiple projects.

### llms-txt/llms.txt.template
Blank structural template for llms.txt files showing the recommended sections and format. Read this file to understand the skeleton structure of an optimized llms.txt file including placeholder sections for project overview, core documentation, functional areas, key concepts, common tasks, and file organization. Use this file as a starting point when creating a new llms.txt file manually or when you want to see the expected structure before auto-generation. Contains placeholder sections including project name and one-sentence description, tech stack and status fields, core documentation section, multiple functional area sections with file path and description placeholders, key concepts section for workflows and patterns, common tasks section for quick references, file organization tree structure, and optional architecture diagram section. Includes metadata fields for last updated date, project version, and status. Follows the format specified in LLM_TXT_STANDARDS.md but with all content as fillable placeholders. Alternative to fully automated generation for those who prefer manual control or want to understand the structure before generating.

### llms-txt/QUICK_REFERENCE.md
One-page cheatsheet of common llms.txt commands and workflows. Read this file for quick access to the most common llms.txt-related commands without reading the full standards document. Use this file when you need a fast reminder of syntax, already understand the concepts, or want a printable reference card. Includes three primary commands (create new, update existing, add new files), template files summary table, recommended setup location advice (keep in ~/templates/llms-txt/ for cross-project access), maintenance commands (after adding files, after refactoring, quality checks), and minimal explanation focused on practical usage. Designed for experienced users who have already read LLM_TXT_STANDARDS.md and just need command syntax reminders. Cross-references the full standards document for detailed explanations.

### llms-txt/prompt.txt
Single-line command to create llms.txt for this templates repository. Read this file to see the exact prompt used to generate the llms.txt file you're currently reading. Contains reference to LLM_TXT_STANDARDS.md and instruction to create llms.txt. Meta-documentation showing the self-referential workflow used to document this repository.

---

## ML Operations Runbooks

### oncall-runbooks/ml_oncall_runbooks_master.md
Comprehensive ML operations runbook with detailed procedures for ML system incidents. Read this file to understand complete step-by-step procedures for handling ML production incidents including model deployment, retraining, monitoring alerts, data pipeline failures, infrastructure scaling, data quality issues, access problems, and incident communication. Use this file when you're on-call for ML systems and need detailed troubleshooting procedures, rollback instructions, or escalation paths. Includes eight major runbook sections: Model Deployment (new model promotion with validation and rollback), Model Retraining and Update (evaluating and promoting retrained versions), Model Monitoring and Alerting (investigating accuracy drops and data drift), Data Pipeline Failure (restoring training/inference data flows), ML Infrastructure Scaling (handling high inference load and latency), Data Quality & Availability (corrupted or missing input features), Access & Permissions (resolving access to model registries and monitoring), and Incident Communication (status updates and stakeholder coordination). Each runbook follows scenario-objective-steps format with specific examples using Iris classifier as reference model. Designed for ML engineers, MLOps teams, and platform engineers supporting production ML systems. More detailed than the short version with full diagnostic procedures.

### oncall-runbooks/ml_oncall_runbooks_master_short.md
Condensed ML operations runbook overview with scenario summaries. Read this file to understand high-level scenarios and objectives for common ML production incidents without detailed step-by-step procedures. Use this file when you need a quick reference to identify which runbook category applies to your incident, or when training new team members on the types of ML incidents to expect. Contains the same eight runbook categories as the master document (Model Deployment, Model Retraining and Update, Model Monitoring and Alerting, Data Pipeline Failure, ML Infrastructure Scaling, Data Quality & Availability, Access & Permissions, Incident Communication) but with only scenario descriptions and objectives, no detailed procedures. Each section includes a concrete example using Iris classifier models (iris_classifier_v1, v2, v3) as reference. Useful as a table of contents or quick triage guide to determine which detailed runbook section to reference. Approximately 48 lines vs 272 lines in the master version.

---

## Cursor AI Rules

### cursor/rules.md
Behavioral guidelines for AI coding assistants in projects. Read this file to understand the core principles and workflows that guide AI behavior including planning before implementation, making small safe changes, test-first development, reading project documentation before coding, and updating project memory after major changes. Use this file when setting up a new project to establish AI agent behavior expectations. Includes eight core principles (think before coding, plan before implementation, prefer small safe changes, never break existing behavior, follow existing patterns, test-first development, update project memory, clear communication), code quality standards for documentation/error handling/security/performance, workflow guidelines for before/during/after development phases, guidance on when to ask questions vs proceeding, and references to project-specific documentation files (coding-standards.md, testing.md, architecture.md, api-contracts.md, deployment.md). Designed to be copied to .cursor/rules.md in downstream projects to control Cursor AI behavior. Promotes thoughtful incremental development with proper documentation and testing rather than rapid potentially-breaking changes. Essential for establishing AI-assisted development standards across projects.

---

## Meta / Continuous Improvement

### meta/system-evolution.md
How this templates repository evolves over time based on real-world usage. Read this file to understand how to identify gaps in templates, update existing templates safely, version the repository, review and improve Cursor rules, capture lessons from real projects, and maintain the template system through regular cadences. Use this file when maintaining or improving this templates repository, planning repository updates, evaluating whether templates need changes, establishing versioning and changelog practices, or defining quality standards for template updates. Includes sections for inputs that signal gaps (project retros, user friction, repeated edits), symptom-to-change mapping (linking friction to template improvements), backwards compatibility principles (safe update practices), template versioning approach (date-based with semantic indicators), Cursor rules evaluation criteria (effectiveness, clarity, completeness), lesson capture workflows (what/where/how to document), maintenance cadence (monthly/quarterly/annual checklists with triggers), version control strategy (git tags and changelog), quality assurance checklist (content, technical, discoverability), and anti-patterns to avoid. Designed for template maintainers and contributors ensuring this repository remains a living system that improves with each project.

### meta/template-retrospective.md
Repeatable retrospective process for improving templates after finishing projects. Read this file to understand when to run retrospectives (end of project, quarterly, post-incident), what questions to ask to identify prompt failures and template gaps, how to analyze root causes and map them to improvement types (update prompt vs template vs rule), and how to create structured improvement queues with validation plans. Use this file when completing projects and want to capture lessons learned, experiencing friction with templates and need structured way to document improvements, running quarterly reviews of template effectiveness, or converting project experiences into template enhancements. Includes sections for retrospective setup (when/who/timing/materials), four-part question framework (what worked, what didn't, missing context, template customizations), decision matrix (root cause to improvement type mapping), output artifacts (improvements queue, validation plan, committed changes), retrospective format variations (quick 30min, standard 1hr, deep 2hr), templates for common scenarios (post-MVP, post-feature, post-incident, quarterly), and follow-up action timelines. Provides concrete symptom catalogs for prompt failures and template gaps. Essential for continuous improvement of this template repository.

### meta/new-project-bootstrap.md
Canonical step-by-step workflow for starting new projects using these templates. Read this file to understand the complete bootstrapping process including copying Cursor rules and project templates, filling placeholders in correct order, running first prompts to orient AI, and completing pre-coding tasks. Use this file when starting any new project, onboarding team members to template workflow, ensuring consistent project setup across organization, or need detailed checklist to avoid missing steps. Includes six phases: copy core files (Cursor rules and project templates with commands), fill core placeholders (llms.txt, memory.md, architecture.md in priority order with time estimates), quick-fill optional templates (decisions.md, roadmap.md, tasks.md), configure standards (coding-standards.md, testing.md, api-contracts.md, deployment.md as patterns emerge), first prompts to run (orient AI, validate setup, plan first feature with exact prompt examples), and first tasks checklist (setup, documentation, first code, validation before coding begins). Includes workflow variations for greenfield projects, existing codebases, team projects, and rapid prototypes with different time investments. Provides troubleshooting guidance and success criteria. Time investment ranges from 15 minutes (minimal) to 2 hours (full setup). Reference this as the authoritative bootstrapping guide.

### meta/prompt-evolution.md
How the prompt library grows and improves over time with quality standards and governance. Read this file to understand prompt quality criteria (specific, context-grounding, format-defining, iterative, failure-aware), naming conventions for general-prompts/ and prompts/ folders, when to create new prompts vs update existing ones, how to retire outdated prompts with deprecation path, and how to test prompts in real projects before adding to library. Use this file when evaluating prompt effectiveness, deciding whether to create new prompt or enhance existing one, maintaining prompt library quality, deprecating or removing prompts, or establishing prompt governance standards. Includes quality checklist (clear objective, explicit context, structured output, examples, edge cases, tested, distinct, concise), anti-patterns to avoid (mega-prompts, vague instructions, missing examples, no grounding, untested), naming conventions for both prompt folders, new prompt template with required sections, update process for minor vs major changes, retirement/deprecation workflow (mark deprecated, provide alternative, grace period, removal), testing protocol (solo validation, revision, second validation, acceptance criteria), lightweight versioning approach (last updated dates, changelog entries), prompt categories (frameworks, roles, learning, orientation, planning, development, quality, maintenance), and monthly/quarterly maintenance cadence. Ensures prompt library remains high-quality and focused.

---

## General AI Prompts

### general-prompts/tcrei-template.md
Universal TCREI prompt template for structured AI requests. Read this file to understand the Task-Context-Reference-Evaluation-Iteration framework for crafting high-quality prompts. Use this template when making complex requests, working on important deliverables, or needing multiple refinement rounds. Template structure: Task (what to produce), Context (audience/goal/constraints), Reference (examples or standards to match), Evaluation (critique and improve output), Iteration (ask what to refine next). Includes example usage and explanation of why each component matters. Works with any AI assistant (ChatGPT, Claude, Cursor). Grounds AI in expectations through examples and forces self-improvement through evaluation step.

### general-prompts/prompt-engineer.md
Meta-prompt for getting AI help to craft better prompts. Read this file to get AI assistance in refining your prompts through iterative questioning and improvement. Use when starting complex tasks, unsure how to phrase requests, want to ensure asking right questions, or need help structuring multi-step prompts. Process: AI asks clarifying questions, suggests improved prompt, repeats until excellent, then executes final prompt. Prevents trying to write perfect prompts yourself by letting AI guide you through best practices and important considerations you might have missed.

### general-prompts/rage-mode.md
Concise prompt format for getting straight answers without fluff. Read this file for a prompt that forces AI to be specific, ask up to 3 clarifying questions, then provide clear answer with 5 concrete steps. Use when needing quick actionable answers, don't have time for explanations, already understand basics, or want specific steps not theory. Prevents AI from being overly verbose, hedging with "it depends" without specifics, or giving generic advice. Example shows difference between verbose generic response vs specific actionable steps.

### general-prompts/systems-architect.md
Prompt for designing production-ready systems with AI acting as senior architect. Read this file to get comprehensive system designs including text-based architecture diagrams, component responsibilities, tradeoffs and alternatives, scaling plans, risks and mitigations, and step-by-step implementation plans. Use when starting new systems, evaluating architectural approaches, explaining architecture to stakeholders, scaling existing systems, or making build vs buy decisions. Provides production-ready designs with consideration of real-world constraints and operational concerns.

### general-prompts/startup-cofounder.md
Validate and refine startup ideas with AI as technical co-founder. Read this file to get structured startup validation including problem clarification, target user identification, market viability evaluation, MVP feature suggestions, monetization strategy, biggest risks, and next 7 actionable steps. Use when validating new ideas, stuck on monetization, need to prioritize features, want outside perspective, or planning MVP scope. Provides concrete next steps to validate ideas before building.

### general-prompts/learning-accelerator.md
Structured learning prompt for mastering new topics quickly. Read this file to get 6-phase learning structure: ELI5 explanation (simple metaphor), professional-level explanation (technical depth), real-world example (practical application), hands-on mini project (learning by doing), common mistakes to avoid (pitfalls), and 3 key takeaways (core concepts). Use when learning new technology, need to understand concepts quickly, preparing for interviews, evaluating whether to adopt tools, or teaching others. Builds intuition with simple explanation then fills in technical depth with examples and practice.

### general-prompts/code-explainer.md
Understand code from a debugging perspective. Read this file to get explanations covering high-level purpose, why each part exists, likely failure points, and improvement suggestions. Use when understanding unfamiliar code, doing code reviews, debugging issues, learning from examples, or refactoring legacy code. Goes beyond what code does to explain intent, potential problems, and better approaches. Helps identify issues before they occur.

### general-prompts/self-critique.md
Improve AI answers through forced self-criticism. Read this file to get a prompt pattern where AI gives best answer, critiques it harshly, identifies gaps and assumptions, then rewrites better version. Use for important decisions, when first answer feels incomplete, need comprehensive answers, or want to ensure nothing missed. First pass often misses nuance; criticism reveals blind spots and produces more thorough second version.

### general-prompts/research-synthesizer.md
Turn research into actionable briefings. Read this file to get structured research summaries including key findings (5-10 main points), consensus (what experts agree on), disagreements (where opinions diverge), implications (what this means), and action steps (what to do next). Use when researching best practices, making informed decisions, need executive summary, evaluating tools/approaches, or creating internal documentation. Distills research into decisions and actions rather than just information.

### general-prompts/speed-summary.md
Fast summarization format for getting to the point. Read this file for ultra-concise summary prompt: 5 bullet points (key information) and 1 "so what" takeaway (why it matters). Use for long documents/articles, meeting notes, research papers, email threads, or technical reports. Includes variations for ultra-fast (one sentence TL;DR) and detailed (10 bullets + takeaways + action items + questions). Saves time when consuming large amounts of information.

### general-prompts/master-framework.md
Comprehensive MASTER framework for complex prompts. Read this file to understand Context-Objective-Role-Constraints-Output format for structured requests. Use for complex strategic questions, multi-faceted problems, need expert-level guidance, lots of context matters, or specific output format needed. Context (background/situation), Objective (what to achieve with success criteria), Role (expertise AI should assume), Constraints (limitations/requirements/boundaries), Output format (response structure). Includes detailed example showing how to apply framework to real scenario (microservice migration).

---

## Cursor Development Prompts

### prompts/understand-codebase.md
Critical first prompt for any new repository. Read this file to get structured prompt for AI to study repository and explain what application does, tech stack used, architecture overview, key entry points, how to run locally, and risky/complex areas. Use as FIRST PROMPT in any new repo, when joining new project, contributing to open source, before making significant changes, or after being away from codebase for months. Builds mental map before making changes. Time investment 2-3 minutes saves hours of fixing bad suggestions based on wrong assumptions. Includes follow-up questions for deeper understanding of user flows, authentication, and dependencies. Combine with architecture.md if it exists to ground AI in documented architecture.

### prompts/repository-map.md
Create structural mental model of codebase. Read this file to get prompt for generating folder structure summary, responsibilities of each major folder, and how key services/modules interact. Use when new to codebase, before starting cross-cutting feature, planning refactoring, documenting for team, or code reviewing structural changes. Gives clear understanding of where things belong and how components relate. Like reading table of contents before reading book. Includes follow-up questions for data flow, specific features, and external dependencies. Use alongside understand-codebase.md: first understand what it does, then understand how it's organized.

### prompts/task-splitter.md
Break large features into small safe completable steps. Read this file to get prompt for decomposing features into steps where each is completable in one session, independently testable, doesn't break existing functionality, and builds logically on previous steps. Use when starting large features, feeling overwhelmed by scope, before sprint planning, breaking down epics, or when estimates are too large. Provides clear scope, definition of done, testing approach, and risk assessment for each step. Includes example showing feature broken from vague "add user profile" into 6 concrete steps. Follow-up questions help identify files to modify, risks, and whether steps can be parallelized. Combine with planning.md to plan implementation for each step.

### prompts/follow-project-rules.md
Ensure AI follows established project patterns and standards. Read this file to get prompt that instructs AI to implement features following rules in architecture.md, coding-standards.md, testing.md, and api-contracts.md while matching existing code style. Use for every feature implementation, when onboarding AI to project, after establishing new standards, when consistency is critical, or working with junior developers. Without this AI invents new patterns and breaks conventions; with this AI follows established practices and maintains consistency. Includes variations for specific standards (coding only, architecture only, testing only) and example showing difference between invented pattern vs following project conventions. Best practice: reference project docs at start of each session to ground AI before making suggestions.

### prompts/update-memory.md
Keep project memory current after completing work. Read this file to get structured prompt for updating memory.md with what was implemented, key decisions made, files changed, remaining work, and notes for future. Use after completing features, making architectural changes, fixing significant bugs, making important decisions, or merging major PRs. Prevents context loss, preserves decisions, documents known issues, and speeds onboarding. Includes detailed example showing what to document (2FA implementation with decisions, files, remaining work, notes). Update at minimum after every merged PR; ideally daily for active development; critically before knowledge transfer. Combine with PR workflow: create PR description with pr-writing.md, then update memory after merging. AI can help draft update which you review and refine.

### prompts/planning.md
Copy-paste prompt for feature planning before implementation. Read this file to get a structured prompt that guides AI through reading relevant documentation (memory.md, architecture.md, decisions.md, tasks.md), creating an implementation plan with files to modify/create and step-by-step approach, identifying existing patterns and dependencies, and noting edge cases and testing strategy. Use this prompt when starting new features, making architectural changes, working on unfamiliar code, handling complex requirements, or before significant refactoring. Ensures alignment and prevents rework by forcing upfront planning. Includes sections explaining why this approach works (prevents rework, reduces bugs, maintains consistency, enables better reviews, documents decisions) and when to use it. Designed for Cursor AI but works with any AI coding assistant. Emphasizes waiting for approval before proceeding with implementation.

### prompts/debugging.md
Systematic debugging prompt for investigating bugs and unexpected behavior. Read this file to get a structured 5-step debugging workflow: gather information (error messages, reproduction steps, recent changes, environment), investigate (review code/tests/docs), form hypotheses about root causes, test hypotheses methodically with logging and minimal reproduction, and propose fix with test to prevent regression. Use this prompt when encountering unexpected behavior, investigating test failures, tracking production issues, understanding complex bugs, or when quick fixes haven't worked. Emphasizes finding root causes instead of treating symptoms and avoiding trial-and-error approaches. Includes tips like starting with error messages, adding logging before changes, testing one hypothesis at a time, and documenting findings for future reference. Prevents jumping to solutions without understanding problems.

### prompts/feature-dev.md
Test-first feature development prompt with incremental implementation workflow. Read this file to get a 5-phase development prompt: context gathering (read architecture.md, coding-standards.md, api-contracts.md, review similar features), write tests first (define acceptance criteria, write failing tests, include edge cases following testing.md), implement incrementally (simplest case first, make tests pass one at a time, small focused commits, follow existing patterns), verify quality (all tests pass, follows standards, complete error handling, acceptable performance), and document (update docs, add comments, update memory.md, note decisions). Use this prompt when building new features, adding enhancements, implementing user stories, developing new components, or extending functionality. Includes checklist for marking features complete (acceptance criteria met, tests passing, follows standards, error handling implemented, docs updated, no regressions, ready for review). Promotes test-driven development and incremental delivery.

### prompts/testing.md
Comprehensive testing prompt for adding tests and improving coverage. Read this file to get a structured 5-step testing workflow: review testing standards (read testing.md, check existing test patterns, understand framework), identify test cases (happy path, edge cases, error conditions, integration points, performance/security), write tests (descriptive names, Arrange-Act-Assert pattern, independent tests, appropriate mocks, deterministic and repeatable), coverage analysis (verify critical paths, check branch coverage, test error handling, validate edge cases), and test maintenance (keep tests simple, avoid testing implementation details, make tests resilient to refactoring, document complex setup). Use this prompt when adding new features test-first, improving coverage for existing code, fixing bugs (write reproducing test first), refactoring (ensure tests pass before and after), or before making risky changes. Includes test quality checklist and guidance on different test types (unit, integration, end-to-end) with appropriate use cases for each.

### prompts/refactoring.md
Safe refactoring prompt for improving code structure without changing behavior. Read this file to get a 5-phase refactoring workflow: ensure test coverage first (verify existing tests pass, add tests if insufficient, document current behavior, establish safety net), plan the refactoring (identify code smells, define target structure, break into small steps, identify risks), refactor incrementally (one small change at a time, run tests after each change, commit working states frequently, never change behavior and structure simultaneously), apply common refactoring patterns (extract function, rename for clarity, remove duplication, simplify conditionals, move code to better location, extract abstraction), and verify/document (all tests still pass, behavior unchanged, code more maintainable, update decisions.md if architecture changed). Use this prompt when code is hard to understand/modify, duplication needs removal, preparing for new features, improving performance/security, simplifying complex logic, or after several bug fixes in same area. Emphasizes Red-Green-Refactor cycle and never wearing the "feature hat" and "refactoring hat" simultaneously. Includes safe refactoring checklist and red flags indicating when to stop and reconsider.

### prompts/pr-writing.md
Comprehensive pull request documentation prompt with structured PR description template. Read this file to get a complete PR writing template including Summary (2-3 sentence overview), Changes (bulleted list of key changes grouped logically), Motivation (why change was needed and problem solved with issue references), Implementation Details (technical approach and non-obvious decisions), Testing (checklist for unit/integration/e2e tests with specific scenarios), Screenshots/Demos (for UI changes), Risks and Considerations (breaking changes, performance, security, deployment concerns), Documentation Updates (checklist for code comments, README, API docs, memory.md), Reviewer Notes (areas needing attention and feedback requests), and Related Links (closes/related issues, dependencies, documentation). Use this prompt when preparing any pull request, code for review, documenting significant changes, or needing stakeholder approval. Includes PR quality checklist, commit message guidelines (50-char imperative titles, body explaining WHY not what), PR size guidelines (ideal 200-400 lines, max 1000), and review request timing best practices. Emphasizes clear context for reviewers to enable faster more thorough reviews.

---

## Project Memory Templates

### project-templates/llms.txt
Blank template for creating AI-readable project maps in downstream projects. Read this file to understand the structure of an llms.txt file that will be copied into new projects to provide AI agents with a comprehensive map of the codebase. Use this file as the starting template when creating llms.txt files for new projects or as reference for the expected format. Contains placeholder sections for project overview (name, tech stack, status, purpose), core documentation (README, memory.md, architecture.md, decisions.md, coding-standards.md, testing.md, api-contracts.md, deployment.md, roadmap.md, tasks.md), functional area groupings with file descriptions, key concepts (workflows and patterns), common tasks (how-to instructions), file organization tree, and environment variables. Follows the optimized llms.txt format defined in llms-txt/LLM_TXT_STANDARDS.md with all content as fillable placeholders marked with [BRACKETS]. Designed to be copied to project root and filled with project-specific details. Essential file for AI-native development providing the entry point for AI agents to understand project structure.

### project-templates/memory.md
Project memory and implementation history template for tracking what has been built and why. Read this file to understand the structure for maintaining a running history of implementations, major changes, and important context for AI agents and developers. Use this file as template when setting up new projects or understanding what to document after completing work. Contains sections for current state (version, last updated, status, what's working, known issues, in progress), implementation history (date-stamped entries with what was built, why, key changes, files affected, notes), architecture evolution (current and past architectures with migration notes), major milestones timeline, deprecated features (what/why removed, replacement, migration path), performance optimizations (problem/solution/impact), security updates, lessons learned, dependencies and integrations (current and removed), data migrations (schema changes with rollback procedures), configuration changes, team context (onboarding notes, tribal knowledge), and future considerations (technical debt, scalability concerns, maintenance reminders). Update guidelines specify when to update (after significant features, architectural changes, important bugs, deprecations, learning lessons). Provides persistent memory that prevents reimplementing features or repeating past mistakes.

### project-templates/architecture.md
System architecture and component relationships template for documenting technical design. Read this file to understand the comprehensive structure for documenting system architecture including components, data flows, infrastructure, and design patterns. Use this file as template when setting up new projects or before making architectural changes. Contains sections for system overview (architecture style, deployment model), architecture diagram (text-based or mermaid showing major components), core components (responsibility, technology, key files, interfaces, dependencies, scalability for each), data flow (step-by-step descriptions of key user flows/processes), data architecture (database schema, caching strategy), API architecture (style, authentication, endpoint groups referencing api-contracts.md), security architecture (authentication/authorization flows, data protection, security boundaries), infrastructure architecture (hosting, compute, networking, storage), async processing (message queues, background jobs), monitoring and observability (logging, metrics, tracing, alerting), design patterns (where used and why), technology decisions (choices with reasons and trade-offs), scalability considerations (current scale, scaling strategy, bottlenecks), disaster recovery (RTO/RPO, backup strategy, failover), integration points (external services, webhooks), and future architecture plans. Cross-references decisions.md for why choices were made and deployment.md for operational details. Essential for understanding system design before implementation.

### project-templates/decisions.md
Architecture Decision Records (ADR) template for documenting why technical decisions were made. Read this file to understand the ADR format based on Michael Nygard's template for capturing important architectural and technical decisions with context and consequences. Use this file when making decisions that are hard to reverse, significantly impact architecture, affect multiple team members, have important trade-offs, or will make future you wonder "why did we do it this way?" Contains sections for active decisions (current decisions guiding the project), superseded decisions (replaced decisions with why), decision categories (infrastructure, data, security, API design, frontend, backend, integration, process), guidelines for writing ADRs (when to write, what makes a good ADR covering context/decision/consequences/alternatives), ADR lifecycle (Proposed, Accepted, Deprecated, Superseded), complete example ADR (ADR-000 about using ADRs itself), and blank ADR template for copying. Each ADR includes Date, Status, Context (forces at play and problem being solved), Decision (what was decided in active voice), Consequences (positive/negative/neutral impacts), and Alternatives Considered (other options and why not chosen). Prevents relitigating decisions by preserving reasoning and constraints. Essential for maintaining technical consistency over time.

### project-templates/roadmap.md
Product roadmap and strategic direction template for communicating vision and planned features. Read this file to understand the comprehensive structure for documenting product vision, quarterly goals, planned features, and strategic initiatives. Use this file when planning new features, communicating direction to stakeholders, or prioritizing work. Contains sections for vision (long-term goal, mission, success criteria), current focus (quarter, theme, key goals, success metrics), roadmap timeline (Now/Next/Later with features including status, problem, solution, impact, dependencies, open questions), feature categories (core/enhancement/nice-to-have with checkboxes), strategic initiatives (goal, why now, scope, timeline, success metrics, key features), user segments and priorities (needs, pain points, planned improvements), technical roadmap (infrastructure, technical debt, performance, security/compliance), dependencies and blockers (external and internal), recently completed (with impact achieved and lessons learned), deferred or cancelled (with reasons), metrics and success (key product metrics table, user feedback trends), decision framework (how features are prioritized using impact/effort/strategic value/user pain/dependencies with optional RICE score table), communication (review frequency, stakeholder updates, transparency approach), and notes/assumptions. Provides product direction context for AI agents to align implementation with strategic goals.

### project-templates/tasks.md
Sprint planning and active task tracking template for managing current work. Read this file to understand the structure for tracking active tasks, sprint planning, backlog management, and work in progress. Use this file during development to understand current priorities, after completing tasks to update status, when planning sprints to organize work, or when blocked to document blockers. Contains sections for current sprint (sprint number/dates, goal, team focus), active tasks by priority (high/medium/low with status emoji, assignee, description, acceptance criteria checkboxes, dependencies, blockers, related links, estimated effort, progress notes), blocked tasks (since when, reason, waiting for, owner, impact), backlog (ready for development, needs refinement, ideas/future), completed this sprint (with dates and assignees, sprint velocity), technical debt (critical/important/nice-to-fix), bug tracking (P0/P1/P2/P3 priority levels), research and spikes (purpose, questions to answer, time box, outcome, status), reviews needed (code/design/documentation), team capacity table (per team member with capacity/allocated/available), sprint planning (definition of ready, definition of done), upcoming work (next sprint candidates, future sprints), task templates (feature/bug fix/technical debt), and notes/decisions (sprint retrospective with what went well, what could improve, action items). Keep synchronized with actual work to provide AI agents with current context.

### project-templates/testing.md
Testing philosophy, standards, and practices template for establishing quality expectations. Read this file to understand comprehensive testing documentation including philosophy, standards, coverage requirements, and best practices across unit/integration/e2e testing. Use this file when writing tests for new features, improving test coverage, fixing bugs (write reproducing test first), before making risky changes, or establishing testing standards for new projects. Contains sections for testing philosophy (core belief, testing goals), testing pyramid (distribution targets 70-80% unit, 15-25% integration, 5-10% e2e), test coverage standards (minimum requirements by category, what must/should/shouldn't be tested), unit testing standards (characteristics, Arrange-Act-Assert structure, naming conventions, mocking strategy), integration testing (what to test including database/API/queues, test environment setup, API testing checklist for all status codes), end-to-end testing (only critical user workflows, tools, best practices, example), test data management (fixtures, database seeding, factories and builders), running tests (local commands for all/specific/coverage/watch, CI/CD pipeline stages and failure policy), test-driven development (Red-Green-Refactor cycle, when to use TDD), continuous testing practices (pre-commit/pre-push/PR checks), testing tools and frameworks, performance testing (load testing, benchmarking), security testing (automated scans, security test cases), flaky tests (prevention and dealing with), test maintenance (when to update/delete), testing checklist (for every feature, bug fix, release), common testing patterns, and troubleshooting test failures. Essential for establishing quality standards that AI agents follow during development.

### project-templates/coding-standards.md
Code style, conventions, and engineering standards template for ensuring consistency. Read this file to understand comprehensive coding standards including general principles, language-specific standards, naming conventions, code organization, functions/methods guidelines, comments/documentation, error handling, testing, security, performance, code review standards, git practices, and dependencies management. Use this file when contributing code to ensure consistency, during code reviews to check standards, when onboarding new developers, or establishing standards for new projects. Contains sections for code quality values (readability first, simplicity, consistency, testability, maintainability), Boy Scout Rule, language-specific standards (style guide, formatter, linter, type checking, key conventions with placeholders for Python/JavaScript/etc), naming conventions (variables, functions, classes, constants, files with ✅/❌ examples), code organization (file structure, import standards, project structure), functions and methods (length < 30 lines, complexity < 10, parameter limits, return value consistency), comments and documentation (when to comment, docstring format, inline comments, TODOs/FIXMEs format), error handling (exceptions vs error codes, guidelines with example, logging errors with log levels), testing standards (quick reference pointing to testing.md), security practices (input validation, authentication/authorization never/always rules, secrets management), performance guidelines (general rules, database query best practices, API call best practices), code review standards (functionality/code quality/testing/security/performance checklist, giving and receiving feedback guidelines), git practices (branch naming, commit messages, pull request requirements), dependencies (adding dependencies checklist, updating process, hygiene), anti-patterns to avoid (code smells, bad practices), configuration (linter, formatter, pre-commit hooks), IDE setup (recommended extensions, settings), and resources. Provides the conventions that AI agents should follow to maintain code quality and consistency.

### project-templates/deployment.md
Deployment processes, environment management, and operational runbook template. Read this file to understand comprehensive deployment documentation including deployment strategy, environments, CI/CD pipeline, database migrations, rollback procedures, infrastructure, configuration, monitoring, and disaster recovery. Use this file when deploying changes, troubleshooting deployment issues, setting up new environments, handling incidents, or establishing deployment processes for new projects. Contains sections for overview (deployment strategy, platform, CI/CD, infrastructure as code), environments (development, staging, production with purpose/URL/database/access/deployment/data for each), deployment process (automated CI/CD with 7 pipeline stages from code quality through post-deployment monitoring, triggering deployments for staging/production, manual deployment for emergencies), database migrations (strategy, tool, creating/running migrations, migration checklist, handling large migrations), rollback procedures (when to rollback, automated and manual rollback steps, database rollback caution), infrastructure (hosting architecture components, infrastructure as code with tool and commands, best practices), configuration management (environment variables required and setting instructions, secrets management tool and access method with rotation frequency), monitoring and alerting (application monitoring tool/dashboard/key metrics, logging tool/levels/viewing commands/retention, alerting tool with critical alerts that page and warning alerts that email/Slack with escalation policy), health checks (endpoint, response format, monitoring frequency), performance optimization (CDN, database, scaling), disaster recovery (backup strategy for database and files with frequency/retention/location, restore procedures with estimated time, RTO/RPO, disaster scenarios with procedures), security (SSL/TLS, firewall rules, access control, security scanning), operational runbooks (common operations like scaling/clearing cache/database maintenance, troubleshooting high error rates/slow performance/deployment failures), maintenance windows, compliance and auditing (audit logging, compliance requirements), useful commands (deployment, database, logs, status), and contact information. Essential for operational context enabling AI agents to understand deployment constraints.

### project-templates/api-contracts.md
API design standards, conventions, and contracts template for consistent API development. Read this file to understand comprehensive API documentation including design standards, endpoint patterns, request/response formats, authentication, error handling, pagination, filtering, versioning, rate limiting, and example requests. Use this file when building new API endpoints, modifying existing APIs, integrating with APIs, during code reviews for API changes, or establishing API standards for new projects. Contains sections for API style (REST/GraphQL/gRPC, version, base URLs for dev/staging/prod), REST API standards (HTTP methods table with idempotent/safe columns, endpoint naming conventions with ✅/❌ examples), URL structure (pattern and examples), request format (required and optional headers, request body JSON format with conventions), response format (success response structure with data/meta, collection response with pagination, error response with error object and details array), status codes (success 2xx, client errors 4xx, server errors 5xx with descriptions), error codes (standard and domain-specific error code tables mapping codes to HTTP status), authentication (method description, JWT authentication example with obtaining token/using token/token refresh), authorization (permission model, roles, checking permissions flow), pagination (query parameters, response with pagination object and links, cursor-based pagination alternative), filtering (query parameters with comparison operators), sorting (query parameter format), field selection (sparse fieldsets), versioning (strategy preferring URL versioning, deprecation policy with example header), rate limiting (limits for authenticated/unauthenticated, headers, rate limit exceeded response with retry-after), CORS (allowed origins, headers), webhooks (registering, payload format, security with signature verification), idempotency (idempotent requests with idempotency-key header), caching (cache headers for different scenarios, conditional requests with ETag), API documentation (OpenAPI/Swagger spec and interactive docs links), API endpoints reference (tables by resource showing method/endpoint/description), testing (tools, example requests with curl), changelog (current version and future versions), and best practices summary. Critical for maintaining API consistency that AI agents follow during API development.

---

## Key Concepts

**Meta-Layer for Continuous Improvement**: The meta/ folder contains workflows that ensure this templates repository evolves based on real-world usage. After completing projects, run meta/template-retrospective.md to identify prompt failures, template gaps, and documentation issues. Apply findings using meta/system-evolution.md guidance (backwards compatibility, versioning, maintenance cadence). Use meta/new-project-bootstrap.md for consistent project setup across all new work. Improve prompts following meta/prompt-evolution.md standards (quality criteria, testing protocol, deprecation path). This creates a feedback loop where every project makes templates better for the next one. The meta layer is for maintaining this repository, not for copying into downstream projects.

**llms.txt Optimization Framework**: The LLM_TXT_STANDARDS.md defines a research-backed approach where "RAG with full documents as retrieval units" enables LLMs to reason about which files to read based on clear descriptions. Optimized descriptions must explain WHEN to read a file (use cases), WHAT you'll learn (specific concepts with function/class names), and WHY it matters (dependencies and relationships). This achieves 95% success rate vs 85% for vector databases or 70% for context stuffing.

**AI-Native Development Template Kit**: The cursor/, prompts/, and project-templates/ folders work together to establish AI-native development practices. cursor/rules.md controls AI agent behavior (plan first, small changes, test-first). The six prompts/ files provide copy-paste workflows for common tasks (planning, debugging, feature development, testing, refactoring, PR writing). The ten project-templates/ files create persistent project memory for AI agents (llms.txt for navigation, memory.md for history, architecture.md for design, decisions.md for rationale, plus standards for testing/coding/deployment/APIs and planning docs like roadmap.md/tasks.md). Together they reduce hallucinations and improve AI coding assistant performance by providing clear context and behavioral expectations.

**Client Retainer Structure**: The three client-docs templates work together to establish and maintain retainer relationships. RETAINER_AGREEMENT.template.md defines the legal and operational framework (hours, SLA, scope). RETAINER_VALUE_ANALYSIS.template.md provides the financial justification and positioning strategy to win the client. MONTHLY_REPORT.template.md demonstrates ongoing value and maintains transparency. Together they support transitioning from unpredictable project work to recurring revenue with 20-40 hour monthly engagements.

**ML Runbook Hierarchy**: The oncall-runbooks follow a two-tier documentation pattern. The short version (ml_oncall_runbooks_master_short.md) serves as triage and orientation, helping oncall engineers quickly identify incident category. The master version (ml_oncall_runbooks_master.md) provides detailed procedures for resolution. Both use concrete examples (Iris classifier v1/v2/v3) to make abstract ML concepts tangible.

**Template Repository Philosophy**: All templates follow a fill-in-the-blank approach with [PLACEHOLDER] syntax making it obvious where customization is needed. They balance comprehensiveness (covering edge cases and details) with usability (clear sections, searchable structure). Templates are designed for direct use, not as examples requiring significant adaptation. Copy templates into new projects and customize for project-specific needs rather than referencing them externally.

---

## Common Tasks

**To set up a new project with AI-native templates**: Follow the canonical workflow in meta/new-project-bootstrap.md for complete step-by-step instructions. Quick version: Copy cursor/rules.md to .cursor/rules.md in the project root. Copy all files from project-templates/ to project root. Fill in placeholders marked with [BRACKETS] in each template file. Start with llms.txt, memory.md, and architecture.md as highest priority. Use prompts/ folder files by referencing them with @ in Cursor (e.g., @prompts/planning.md) or copy-paste as needed during development.

**To create an llms.txt file for a new project**: Reference the LLM_TXT_STANDARDS.md file and use the command pattern shown in CREATE_LLM_TXT.md. Either auto-generate by having an AI scan all files and create descriptions following the standards, or manually fill in llms.txt.template with project-specific details. Optimize descriptions to explain when/what/why for each file.

**To use the development prompts effectively**: Start every new codebase with @prompts/understand-codebase.md then @prompts/repository-map.md to build context. Reference prompts using @ syntax in Cursor before starting work. Use @prompts/planning.md or @prompts/task-splitter.md before implementing features. Use @prompts/follow-project-rules.md to ensure AI follows your architecture and standards. Use @prompts/debugging.md when investigating bugs. Use @prompts/feature-dev.md for test-first development. Use @prompts/refactoring.md before restructuring code. Use @prompts/pr-writing.md when creating pull requests, then @prompts/update-memory.md after merging. The prompts guide AI agents through best-practice workflows for each task type.

**To use general AI prompts**: Reference prompts from general-prompts/ folder for any AI assistant (ChatGPT, Claude, etc). Use @general-prompts/tcrei-template.md or @general-prompts/master-framework.md for complex requests. Use @general-prompts/rage-mode.md when you need quick actionable answers. Use @general-prompts/systems-architect.md for designing systems, @general-prompts/startup-cofounder.md for validating ideas, or @general-prompts/learning-accelerator.md for mastering new topics. Use @general-prompts/self-critique.md for important work needing extra thoroughness. Use @general-prompts/prompt-engineer.md to get AI help crafting better prompts. See PROMPT_PLAYBOOK.md for complete index and usage patterns.

**To prepare a monthly client report**: Copy MONTHLY_REPORT.template.md to a new file with naming pattern like "2025-10-ClientName-Monthly-Report.md". Fill in all bracketed placeholders starting with executive summary (hours used/remaining, key accomplishments), then detailed time logs, work completed by category, system metrics if applicable, costs, and upcoming work. Deliver by the agreed date each month (typically 1st-5th of following month).

**To pitch a retainer agreement**: Start with RETAINER_VALUE_ANALYSIS.template.md to calculate the financial model and prepare your positioning. Use the "What You Say to [Client Contact]" script to frame the proposal. Present RETAINER_AGREEMENT.template.md as the formal contract after verbal agreement. Emphasize predictability for client (fixed costs) and immediate value (first project included saves money vs standalone pricing).

**To handle an ML production incident**: First reference oncall-runbooks/ml_oncall_runbooks_master_short.md to identify which of the 8 runbook categories matches your incident (deployment, monitoring, data pipeline, scaling, data quality, access, or communication). Then open the corresponding section in ml_oncall_runbooks_master.md for detailed diagnostic steps, commands, and rollback procedures.

**To maintain llms.txt files**: Update whenever you add new files, refactor architecture, or add major features. Use the optimization checklist in LLM_TXT_STANDARDS.md to audit quality. Test by asking an AI to solve a task using only your llms.txt and observe if it retrieves the right files. Common maintenance triggers include adding 5+ new files, changing file organization, or updating function signatures referenced in descriptions.

**To improve this templates repository**: After completing projects, run meta/template-retrospective.md to capture lessons learned. Identify prompt failures, template gaps, and documentation issues. Follow meta/system-evolution.md for guidance on updating templates safely, maintaining backwards compatibility, and versioning changes. Use meta/prompt-evolution.md to evaluate and improve prompt quality. Schedule monthly quick-checks and quarterly thorough reviews to keep templates current and effective.

---

## File Organization

```
templates/
├── cursor/                    # Cursor AI behavioral rules
│   └── rules.md              # Copy to .cursor/rules.md in projects
├── meta/                      # Continuous improvement workflows
│   ├── system-evolution.md   # How templates repository evolves
│   ├── template-retrospective.md  # Post-project improvement process
│   ├── new-project-bootstrap.md   # Canonical project setup workflow
│   └── prompt-evolution.md   # Prompt library governance
├── general-prompts/           # General AI prompts (ChatGPT, Claude, etc)
│   ├── tcrei-template.md     # TCREI structured prompt template
│   ├── prompt-engineer.md    # Get AI help crafting prompts
│   ├── rage-mode.md          # Straight answers, no fluff
│   ├── systems-architect.md  # Design production systems
│   ├── startup-cofounder.md  # Validate startup ideas
│   ├── learning-accelerator.md  # Master topics quickly
│   ├── code-explainer.md     # Understand code deeply
│   ├── self-critique.md      # Improve AI answers
│   ├── research-synthesizer.md  # Research briefings
│   ├── speed-summary.md      # Fast summarization
│   └── master-framework.md   # Comprehensive prompt structure
├── prompts/                   # Cursor development prompts
│   ├── understand-codebase.md  # First prompt in any repo
│   ├── repository-map.md     # Understand folder structure
│   ├── task-splitter.md      # Break features into steps
│   ├── follow-project-rules.md  # Follow architecture/standards
│   ├── update-memory.md      # Keep memory.md current
│   ├── planning.md           # Feature planning workflow
│   ├── debugging.md          # Systematic debugging
│   ├── feature-dev.md        # Test-first feature development
│   ├── testing.md            # Comprehensive testing
│   ├── refactoring.md        # Safe refactoring process
│   └── pr-writing.md         # Pull request documentation
├── project-templates/         # Project memory and documentation templates
│   ├── llms.txt              # AI-readable project map template
│   ├── memory.md             # Implementation history template
│   ├── architecture.md       # System architecture template
│   ├── decisions.md          # Architecture Decision Records template
│   ├── roadmap.md            # Product roadmap template
│   ├── tasks.md              # Sprint and task tracking template
│   ├── testing.md            # Testing standards template
│   ├── coding-standards.md   # Code conventions template
│   ├── deployment.md         # Deployment processes template
│   └── api-contracts.md      # API design standards template
├── client-docs/               # Client relationship templates
│   ├── MONTHLY_REPORT.template.md
│   ├── RETAINER_AGREEMENT.template.md
│   └── RETAINER_VALUE_ANALYSIS.template.md
├── llms-txt/                   # llms.txt creation framework
│   ├── LLM_TXT_STANDARDS.md  # Best practices and standards
│   ├── CREATE_LLM_TXT.md     # Quick creation guide
│   ├── llms.txt.template     # Blank structural template
│   ├── prompt.txt            # Single-line creation command
│   └── QUICK_REFERENCE.md    # Command cheatsheet
├── oncall-runbooks/           # ML operations runbooks
│   ├── ml_oncall_runbooks_master.md
│   └── ml_oncall_runbooks_master_short.md
├── README.md                  # Repository overview and usage guide
├── QUICK_START.md            # Quick start guide for using templates
├── EXISTING_PROJECT_GUIDE.md # Guide for adopting templates in existing projects
├── PROMPT_PLAYBOOK.md        # Index of all prompts with quick reference
├── llms.txt                   # This file - repository documentation map
└── AI_REPO_CONTEXT.md        # Context for generating this template repository
```

---

**Last Updated**: February 14, 2026
**Repository Status**: Active template collection
**Usage**: Copy templates to new projects and customize placeholders


