# Templates Repository

> Collection of reusable templates for client documentation, llms.txt creation, and ML operations runbooks.

## Project Overview

**Tech Stack**: Markdown templates
**Status**: Production-ready collection
**Purpose**: Provides standardized templates for client communication, AI-assisted development workflows, and machine learning operations documentation

---

## Core Documentation

### README.md
Minimal project README at repository root. Read this file to understand the basic structure of the repository. Currently only contains the repository title.

---

## Client Documentation Templates

### client-docs/MONTHLY_REPORT.template.md
Comprehensive monthly development report template for retainer clients. Read this file to understand how to structure detailed monthly reports including hours breakdown, work completed, system health metrics, infrastructure costs, support tickets, security updates, upcoming work, recommendations, and client action items. Use this template when preparing monthly status reports for retainer-based development partnerships. Includes sections for time allocation tables, detailed time logs, work categorization (bug fixes, enhancements, new features, security), performance metrics, database statistics, cost tracking, and risk assessment. Essential for maintaining transparent client relationships and demonstrating value delivered. Designed for consultants and agencies on monthly retainer agreements tracking 20-40+ hours of work per month.

### client-docs/RETAINER_AGREEMENT.template.md
Complete retainer agreement template for development partnership contracts. Read this file to understand how to structure long-term development retainer agreements including scope of services, SLA definitions, hours management, payment terms, and deliverables. Use this template when establishing or formalizing ongoing development partnerships with clients. Includes sections for duration and auto-renewal terms, monthly investment structure, response time SLAs by priority level (Critical/High/Medium/Low), hours rollover policies, out-of-scope definitions, technology stack coverage, quarterly planning frameworks, value proposition comparisons, intellectual property terms, confidentiality clauses, and termination conditions. Covers both technical partnership aspects (proactive monitoring, strategic consultation) and business terms (billing, liability, insurance). Designed to replace project-by-project contracts with predictable recurring revenue relationships.

### client-docs/RETAINER_VALUE_ANALYSIS.template.md
Financial and strategic analysis template for positioning retainer agreements. Read this file to understand how to calculate, present, and justify retainer pricing from both consultant and client perspectives including revenue comparison scenarios, effective hourly rates, risk mitigation strategies, and ROI demonstrations. Use this template when preparing to pitch a retainer agreement to a client, analyzing whether a retainer makes financial sense, or positioning the value proposition. Includes detailed math breakdowns comparing retainer vs project-based revenue models, cost comparison tables (retainer vs part-time hire vs agency vs full-time), client value proposition frameworks, efficiency gains analysis, time breakdown calculations, effective rate scenarios (conservative/average/high usage), risk mitigation strategies for both parties, objection handling responses ("seems too expensive", "what if no work", "can I cancel"), success metrics definitions, and positioning conversation scripts. Particularly valuable for freelancers and agencies transitioning from project work to recurring revenue models. Shows how to frame a $3-8K/month retainer as cost savings for clients while providing revenue stability for consultants.

---

## llms.txt Creation Framework

### llms-txt/LLM_TXT_STANDARDS.md
Research-backed best practices and standards for creating optimized llms.txt files that maximize AI code agent performance. Read this file to understand why optimized llms.txt files outperform vector databases (95% vs 85% success rate), how to write effective file descriptions, proper structure and formatting rules, and quality optimization checklists. Use this file when creating new llms.txt files, optimizing existing ones, or teaching others about effective AI-assisted development workflows. Includes the file description template format (opening statement + primary concepts + use cases + specific functions + dependencies), structure guidelines for project overview and functional area organization, reasoning-friendly language patterns (verb-based descriptions starting with "Read this file to...", "Reference this for...", "Use when..."), anti-patterns to avoid (generic descriptions, missing context, listings without explanation), size guidelines (5,000-20,000 tokens optimal), maintenance triggers (when to update), and real-world examples of well-optimized vs poorly-optimized entries. Based on empirical research by Lance Martin showing clear descriptions enable better retrieval decisions. Critical reference for anyone implementing llms.txt in their projects. Explains why "RAG with full documents as retrieval units" outperforms context stuffing and standard documentation approaches.

### llms-txt/CREATE_LLM_TXT.md
Simple instruction guide for AI assistants to create llms.txt files using LLM_TXT_STANDARDS.md. Read this file to understand the quick commands and workflows for generating optimized llms.txt files automatically. Use this file when you want to quickly create or update an llms.txt file by providing it to an AI assistant along with the standards document. Includes three main usage patterns: full auto-generation (scan all files and create from scratch), update existing llms.txt (optimize current file), and add specific files (update with new additions). Provides copy-paste commands, expected output structure preview, tips for best results, and recommendations for file placement (shared templates in central location vs copied to each project). Designed to minimize friction in llms.txt adoption by reducing the task to a single command. References LLM_TXT_STANDARDS.md as the source of truth. Useful for teams implementing llms.txt workflows across multiple projects.

### llms-txt/llms.txt.template
Blank structural template for llms.txt files showing the recommended sections and format. Read this file to understand the skeleton structure of an optimized llms.txt file including placeholder sections for project overview, core documentation, functional areas, key concepts, common tasks, and file organization. Use this file as a starting point when creating a new llms.txt file manually or when you want to see the expected structure before auto-generation. Contains placeholder sections including project name and one-sentence description, tech stack and status fields, core documentation section, multiple functional area sections with file path and description placeholders, key concepts section for workflows and patterns, common tasks section for quick references, file organization tree structure, and optional architecture diagram section. Includes metadata fields for last updated date, project version, and status. Follows the format specified in LLM_TXT_STANDARDS.md but with all content as fillable placeholders. Alternative to fully automated generation for those who prefer manual control or want to understand the structure before generating.

### llms-txt/QUICK_REFERENCE.md
One-page cheatsheet of common llms.txt commands and workflows. Read this file for quick access to the most common llms.txt-related commands without reading the full standards document. Use this file when you need a fast reminder of syntax, already understand the concepts, or want a printable reference card. Includes three primary commands (create new, update existing, add new files), template files summary table, recommended setup location advice (keep in ~/templates/llms-txt/ for cross-project access), maintenance commands (after adding files, after refactoring, quality checks), and minimal explanation focused on practical usage. Designed for experienced users who have already read LLM_TXT_STANDARDS.md and just need command syntax reminders. Cross-references the full standards document for detailed explanations.

### llms-txt/prompt.txt
Single-line command to create llms.txt for this templates repository. Read this file to see the exact prompt used to generate the llms.txt file you're currently reading. Contains reference to LLM_TXT_STANDARDS.md and instruction to create llms.txt. Meta-documentation showing the self-referential workflow used to document this repository.

---

## ML Operations Runbooks

### oncall-runbooks/ml_oncall_runbooks_master.md
Comprehensive ML operations runbook with detailed procedures for ML system incidents. Read this file to understand complete step-by-step procedures for handling ML production incidents including model deployment, retraining, monitoring alerts, data pipeline failures, infrastructure scaling, data quality issues, access problems, and incident communication. Use this file when you're on-call for ML systems and need detailed troubleshooting procedures, rollback instructions, or escalation paths. Includes eight major runbook sections: Model Deployment (new model promotion with validation and rollback), Model Retraining and Update (evaluating and promoting retrained versions), Model Monitoring and Alerting (investigating accuracy drops and data drift), Data Pipeline Failure (restoring training/inference data flows), ML Infrastructure Scaling (handling high inference load and latency), Data Quality & Availability (corrupted or missing input features), Access & Permissions (resolving access to model registries and monitoring), and Incident Communication (status updates and stakeholder coordination). Each runbook follows scenario-objective-steps format with specific examples using Iris classifier as reference model. Designed for ML engineers, MLOps teams, and platform engineers supporting production ML systems. More detailed than the short version with full diagnostic procedures.

### oncall-runbooks/ml_oncall_runbooks_master_short.md
Condensed ML operations runbook overview with scenario summaries. Read this file to understand high-level scenarios and objectives for common ML production incidents without detailed step-by-step procedures. Use this file when you need a quick reference to identify which runbook category applies to your incident, or when training new team members on the types of ML incidents to expect. Contains the same eight runbook categories as the master document (Model Deployment, Model Retraining and Update, Model Monitoring and Alerting, Data Pipeline Failure, ML Infrastructure Scaling, Data Quality & Availability, Access & Permissions, Incident Communication) but with only scenario descriptions and objectives, no detailed procedures. Each section includes a concrete example using Iris classifier models (iris_classifier_v1, v2, v3) as reference. Useful as a table of contents or quick triage guide to determine which detailed runbook section to reference. Approximately 48 lines vs 272 lines in the master version.

---

## Cursor AI Rules

### cursor/rules.md
Behavioral guidelines for AI coding assistants in projects. Read this file to understand the core principles and workflows that guide AI behavior including planning before implementation, making small safe changes, test-first development, reading project documentation before coding, and updating project memory after major changes. Use this file when setting up a new project to establish AI agent behavior expectations. Includes eight core principles (think before coding, plan before implementation, prefer small safe changes, never break existing behavior, follow existing patterns, test-first development, update project memory, clear communication), code quality standards for documentation/error handling/security/performance, workflow guidelines for before/during/after development phases, guidance on when to ask questions vs proceeding, and references to project-specific documentation files (coding-standards.md, testing.md, architecture.md, api-contracts.md, deployment.md). Designed to be copied to .cursor/rules.md in downstream projects to control Cursor AI behavior. Promotes thoughtful incremental development with proper documentation and testing rather than rapid potentially-breaking changes. Essential for establishing AI-assisted development standards across projects.

---

## Reusable Prompts

### prompts/planning.md
Copy-paste prompt for feature planning before implementation. Read this file to get a structured prompt that guides AI through reading relevant documentation (memory.md, architecture.md, decisions.md, tasks.md), creating an implementation plan with files to modify/create and step-by-step approach, identifying existing patterns and dependencies, and noting edge cases and testing strategy. Use this prompt when starting new features, making architectural changes, working on unfamiliar code, handling complex requirements, or before significant refactoring. Ensures alignment and prevents rework by forcing upfront planning. Includes sections explaining why this approach works (prevents rework, reduces bugs, maintains consistency, enables better reviews, documents decisions) and when to use it. Designed for Cursor AI but works with any AI coding assistant. Emphasizes waiting for approval before proceeding with implementation.

### prompts/debugging.md
Systematic debugging prompt for investigating bugs and unexpected behavior. Read this file to get a structured 5-step debugging workflow: gather information (error messages, reproduction steps, recent changes, environment), investigate (review code/tests/docs), form hypotheses about root causes, test hypotheses methodically with logging and minimal reproduction, and propose fix with test to prevent regression. Use this prompt when encountering unexpected behavior, investigating test failures, tracking production issues, understanding complex bugs, or when quick fixes haven't worked. Emphasizes finding root causes instead of treating symptoms and avoiding trial-and-error approaches. Includes tips like starting with error messages, adding logging before changes, testing one hypothesis at a time, and documenting findings for future reference. Prevents jumping to solutions without understanding problems.

### prompts/feature-dev.md
Test-first feature development prompt with incremental implementation workflow. Read this file to get a 5-phase development prompt: context gathering (read architecture.md, coding-standards.md, api-contracts.md, review similar features), write tests first (define acceptance criteria, write failing tests, include edge cases following testing.md), implement incrementally (simplest case first, make tests pass one at a time, small focused commits, follow existing patterns), verify quality (all tests pass, follows standards, complete error handling, acceptable performance), and document (update docs, add comments, update memory.md, note decisions). Use this prompt when building new features, adding enhancements, implementing user stories, developing new components, or extending functionality. Includes checklist for marking features complete (acceptance criteria met, tests passing, follows standards, error handling implemented, docs updated, no regressions, ready for review). Promotes test-driven development and incremental delivery.

### prompts/testing.md
Comprehensive testing prompt for adding tests and improving coverage. Read this file to get a structured 5-step testing workflow: review testing standards (read testing.md, check existing test patterns, understand framework), identify test cases (happy path, edge cases, error conditions, integration points, performance/security), write tests (descriptive names, Arrange-Act-Assert pattern, independent tests, appropriate mocks, deterministic and repeatable), coverage analysis (verify critical paths, check branch coverage, test error handling, validate edge cases), and test maintenance (keep tests simple, avoid testing implementation details, make tests resilient to refactoring, document complex setup). Use this prompt when adding new features test-first, improving coverage for existing code, fixing bugs (write reproducing test first), refactoring (ensure tests pass before and after), or before making risky changes. Includes test quality checklist and guidance on different test types (unit, integration, end-to-end) with appropriate use cases for each.

### prompts/refactoring.md
Safe refactoring prompt for improving code structure without changing behavior. Read this file to get a 5-phase refactoring workflow: ensure test coverage first (verify existing tests pass, add tests if insufficient, document current behavior, establish safety net), plan the refactoring (identify code smells, define target structure, break into small steps, identify risks), refactor incrementally (one small change at a time, run tests after each change, commit working states frequently, never change behavior and structure simultaneously), apply common refactoring patterns (extract function, rename for clarity, remove duplication, simplify conditionals, move code to better location, extract abstraction), and verify/document (all tests still pass, behavior unchanged, code more maintainable, update decisions.md if architecture changed). Use this prompt when code is hard to understand/modify, duplication needs removal, preparing for new features, improving performance/security, simplifying complex logic, or after several bug fixes in same area. Emphasizes Red-Green-Refactor cycle and never wearing the "feature hat" and "refactoring hat" simultaneously. Includes safe refactoring checklist and red flags indicating when to stop and reconsider.

### prompts/pr-writing.md
Comprehensive pull request documentation prompt with structured PR description template. Read this file to get a complete PR writing template including Summary (2-3 sentence overview), Changes (bulleted list of key changes grouped logically), Motivation (why change was needed and problem solved with issue references), Implementation Details (technical approach and non-obvious decisions), Testing (checklist for unit/integration/e2e tests with specific scenarios), Screenshots/Demos (for UI changes), Risks and Considerations (breaking changes, performance, security, deployment concerns), Documentation Updates (checklist for code comments, README, API docs, memory.md), Reviewer Notes (areas needing attention and feedback requests), and Related Links (closes/related issues, dependencies, documentation). Use this prompt when preparing any pull request, code for review, documenting significant changes, or needing stakeholder approval. Includes PR quality checklist, commit message guidelines (50-char imperative titles, body explaining WHY not what), PR size guidelines (ideal 200-400 lines, max 1000), and review request timing best practices. Emphasizes clear context for reviewers to enable faster more thorough reviews.

---

## Project Memory Templates

### project-templates/llms.txt
Blank template for creating AI-readable project maps in downstream projects. Read this file to understand the structure of an llms.txt file that will be copied into new projects to provide AI agents with a comprehensive map of the codebase. Use this file as the starting template when creating llms.txt files for new projects or as reference for the expected format. Contains placeholder sections for project overview (name, tech stack, status, purpose), core documentation (README, memory.md, architecture.md, decisions.md, coding-standards.md, testing.md, api-contracts.md, deployment.md, roadmap.md, tasks.md), functional area groupings with file descriptions, key concepts (workflows and patterns), common tasks (how-to instructions), file organization tree, and environment variables. Follows the optimized llms.txt format defined in llms-txt/LLM_TXT_STANDARDS.md with all content as fillable placeholders marked with [BRACKETS]. Designed to be copied to project root and filled with project-specific details. Essential file for AI-native development providing the entry point for AI agents to understand project structure.

### project-templates/memory.md
Project memory and implementation history template for tracking what has been built and why. Read this file to understand the structure for maintaining a running history of implementations, major changes, and important context for AI agents and developers. Use this file as template when setting up new projects or understanding what to document after completing work. Contains sections for current state (version, last updated, status, what's working, known issues, in progress), implementation history (date-stamped entries with what was built, why, key changes, files affected, notes), architecture evolution (current and past architectures with migration notes), major milestones timeline, deprecated features (what/why removed, replacement, migration path), performance optimizations (problem/solution/impact), security updates, lessons learned, dependencies and integrations (current and removed), data migrations (schema changes with rollback procedures), configuration changes, team context (onboarding notes, tribal knowledge), and future considerations (technical debt, scalability concerns, maintenance reminders). Update guidelines specify when to update (after significant features, architectural changes, important bugs, deprecations, learning lessons). Provides persistent memory that prevents reimplementing features or repeating past mistakes.

### project-templates/architecture.md
System architecture and component relationships template for documenting technical design. Read this file to understand the comprehensive structure for documenting system architecture including components, data flows, infrastructure, and design patterns. Use this file as template when setting up new projects or before making architectural changes. Contains sections for system overview (architecture style, deployment model), architecture diagram (text-based or mermaid showing major components), core components (responsibility, technology, key files, interfaces, dependencies, scalability for each), data flow (step-by-step descriptions of key user flows/processes), data architecture (database schema, caching strategy), API architecture (style, authentication, endpoint groups referencing api-contracts.md), security architecture (authentication/authorization flows, data protection, security boundaries), infrastructure architecture (hosting, compute, networking, storage), async processing (message queues, background jobs), monitoring and observability (logging, metrics, tracing, alerting), design patterns (where used and why), technology decisions (choices with reasons and trade-offs), scalability considerations (current scale, scaling strategy, bottlenecks), disaster recovery (RTO/RPO, backup strategy, failover), integration points (external services, webhooks), and future architecture plans. Cross-references decisions.md for why choices were made and deployment.md for operational details. Essential for understanding system design before implementation.

### project-templates/decisions.md
Architecture Decision Records (ADR) template for documenting why technical decisions were made. Read this file to understand the ADR format based on Michael Nygard's template for capturing important architectural and technical decisions with context and consequences. Use this file when making decisions that are hard to reverse, significantly impact architecture, affect multiple team members, have important trade-offs, or will make future you wonder "why did we do it this way?" Contains sections for active decisions (current decisions guiding the project), superseded decisions (replaced decisions with why), decision categories (infrastructure, data, security, API design, frontend, backend, integration, process), guidelines for writing ADRs (when to write, what makes a good ADR covering context/decision/consequences/alternatives), ADR lifecycle (Proposed, Accepted, Deprecated, Superseded), complete example ADR (ADR-000 about using ADRs itself), and blank ADR template for copying. Each ADR includes Date, Status, Context (forces at play and problem being solved), Decision (what was decided in active voice), Consequences (positive/negative/neutral impacts), and Alternatives Considered (other options and why not chosen). Prevents relitigating decisions by preserving reasoning and constraints. Essential for maintaining technical consistency over time.

### project-templates/roadmap.md
Product roadmap and strategic direction template for communicating vision and planned features. Read this file to understand the comprehensive structure for documenting product vision, quarterly goals, planned features, and strategic initiatives. Use this file when planning new features, communicating direction to stakeholders, or prioritizing work. Contains sections for vision (long-term goal, mission, success criteria), current focus (quarter, theme, key goals, success metrics), roadmap timeline (Now/Next/Later with features including status, problem, solution, impact, dependencies, open questions), feature categories (core/enhancement/nice-to-have with checkboxes), strategic initiatives (goal, why now, scope, timeline, success metrics, key features), user segments and priorities (needs, pain points, planned improvements), technical roadmap (infrastructure, technical debt, performance, security/compliance), dependencies and blockers (external and internal), recently completed (with impact achieved and lessons learned), deferred or cancelled (with reasons), metrics and success (key product metrics table, user feedback trends), decision framework (how features are prioritized using impact/effort/strategic value/user pain/dependencies with optional RICE score table), communication (review frequency, stakeholder updates, transparency approach), and notes/assumptions. Provides product direction context for AI agents to align implementation with strategic goals.

### project-templates/tasks.md
Sprint planning and active task tracking template for managing current work. Read this file to understand the structure for tracking active tasks, sprint planning, backlog management, and work in progress. Use this file during development to understand current priorities, after completing tasks to update status, when planning sprints to organize work, or when blocked to document blockers. Contains sections for current sprint (sprint number/dates, goal, team focus), active tasks by priority (high/medium/low with status emoji, assignee, description, acceptance criteria checkboxes, dependencies, blockers, related links, estimated effort, progress notes), blocked tasks (since when, reason, waiting for, owner, impact), backlog (ready for development, needs refinement, ideas/future), completed this sprint (with dates and assignees, sprint velocity), technical debt (critical/important/nice-to-fix), bug tracking (P0/P1/P2/P3 priority levels), research and spikes (purpose, questions to answer, time box, outcome, status), reviews needed (code/design/documentation), team capacity table (per team member with capacity/allocated/available), sprint planning (definition of ready, definition of done), upcoming work (next sprint candidates, future sprints), task templates (feature/bug fix/technical debt), and notes/decisions (sprint retrospective with what went well, what could improve, action items). Keep synchronized with actual work to provide AI agents with current context.

### project-templates/testing.md
Testing philosophy, standards, and practices template for establishing quality expectations. Read this file to understand comprehensive testing documentation including philosophy, standards, coverage requirements, and best practices across unit/integration/e2e testing. Use this file when writing tests for new features, improving test coverage, fixing bugs (write reproducing test first), before making risky changes, or establishing testing standards for new projects. Contains sections for testing philosophy (core belief, testing goals), testing pyramid (distribution targets 70-80% unit, 15-25% integration, 5-10% e2e), test coverage standards (minimum requirements by category, what must/should/shouldn't be tested), unit testing standards (characteristics, Arrange-Act-Assert structure, naming conventions, mocking strategy), integration testing (what to test including database/API/queues, test environment setup, API testing checklist for all status codes), end-to-end testing (only critical user workflows, tools, best practices, example), test data management (fixtures, database seeding, factories and builders), running tests (local commands for all/specific/coverage/watch, CI/CD pipeline stages and failure policy), test-driven development (Red-Green-Refactor cycle, when to use TDD), continuous testing practices (pre-commit/pre-push/PR checks), testing tools and frameworks, performance testing (load testing, benchmarking), security testing (automated scans, security test cases), flaky tests (prevention and dealing with), test maintenance (when to update/delete), testing checklist (for every feature, bug fix, release), common testing patterns, and troubleshooting test failures. Essential for establishing quality standards that AI agents follow during development.

### project-templates/coding-standards.md
Code style, conventions, and engineering standards template for ensuring consistency. Read this file to understand comprehensive coding standards including general principles, language-specific standards, naming conventions, code organization, functions/methods guidelines, comments/documentation, error handling, testing, security, performance, code review standards, git practices, and dependencies management. Use this file when contributing code to ensure consistency, during code reviews to check standards, when onboarding new developers, or establishing standards for new projects. Contains sections for code quality values (readability first, simplicity, consistency, testability, maintainability), Boy Scout Rule, language-specific standards (style guide, formatter, linter, type checking, key conventions with placeholders for Python/JavaScript/etc), naming conventions (variables, functions, classes, constants, files with ✅/❌ examples), code organization (file structure, import standards, project structure), functions and methods (length < 30 lines, complexity < 10, parameter limits, return value consistency), comments and documentation (when to comment, docstring format, inline comments, TODOs/FIXMEs format), error handling (exceptions vs error codes, guidelines with example, logging errors with log levels), testing standards (quick reference pointing to testing.md), security practices (input validation, authentication/authorization never/always rules, secrets management), performance guidelines (general rules, database query best practices, API call best practices), code review standards (functionality/code quality/testing/security/performance checklist, giving and receiving feedback guidelines), git practices (branch naming, commit messages, pull request requirements), dependencies (adding dependencies checklist, updating process, hygiene), anti-patterns to avoid (code smells, bad practices), configuration (linter, formatter, pre-commit hooks), IDE setup (recommended extensions, settings), and resources. Provides the conventions that AI agents should follow to maintain code quality and consistency.

### project-templates/deployment.md
Deployment processes, environment management, and operational runbook template. Read this file to understand comprehensive deployment documentation including deployment strategy, environments, CI/CD pipeline, database migrations, rollback procedures, infrastructure, configuration, monitoring, and disaster recovery. Use this file when deploying changes, troubleshooting deployment issues, setting up new environments, handling incidents, or establishing deployment processes for new projects. Contains sections for overview (deployment strategy, platform, CI/CD, infrastructure as code), environments (development, staging, production with purpose/URL/database/access/deployment/data for each), deployment process (automated CI/CD with 7 pipeline stages from code quality through post-deployment monitoring, triggering deployments for staging/production, manual deployment for emergencies), database migrations (strategy, tool, creating/running migrations, migration checklist, handling large migrations), rollback procedures (when to rollback, automated and manual rollback steps, database rollback caution), infrastructure (hosting architecture components, infrastructure as code with tool and commands, best practices), configuration management (environment variables required and setting instructions, secrets management tool and access method with rotation frequency), monitoring and alerting (application monitoring tool/dashboard/key metrics, logging tool/levels/viewing commands/retention, alerting tool with critical alerts that page and warning alerts that email/Slack with escalation policy), health checks (endpoint, response format, monitoring frequency), performance optimization (CDN, database, scaling), disaster recovery (backup strategy for database and files with frequency/retention/location, restore procedures with estimated time, RTO/RPO, disaster scenarios with procedures), security (SSL/TLS, firewall rules, access control, security scanning), operational runbooks (common operations like scaling/clearing cache/database maintenance, troubleshooting high error rates/slow performance/deployment failures), maintenance windows, compliance and auditing (audit logging, compliance requirements), useful commands (deployment, database, logs, status), and contact information. Essential for operational context enabling AI agents to understand deployment constraints.

### project-templates/api-contracts.md
API design standards, conventions, and contracts template for consistent API development. Read this file to understand comprehensive API documentation including design standards, endpoint patterns, request/response formats, authentication, error handling, pagination, filtering, versioning, rate limiting, and example requests. Use this file when building new API endpoints, modifying existing APIs, integrating with APIs, during code reviews for API changes, or establishing API standards for new projects. Contains sections for API style (REST/GraphQL/gRPC, version, base URLs for dev/staging/prod), REST API standards (HTTP methods table with idempotent/safe columns, endpoint naming conventions with ✅/❌ examples), URL structure (pattern and examples), request format (required and optional headers, request body JSON format with conventions), response format (success response structure with data/meta, collection response with pagination, error response with error object and details array), status codes (success 2xx, client errors 4xx, server errors 5xx with descriptions), error codes (standard and domain-specific error code tables mapping codes to HTTP status), authentication (method description, JWT authentication example with obtaining token/using token/token refresh), authorization (permission model, roles, checking permissions flow), pagination (query parameters, response with pagination object and links, cursor-based pagination alternative), filtering (query parameters with comparison operators), sorting (query parameter format), field selection (sparse fieldsets), versioning (strategy preferring URL versioning, deprecation policy with example header), rate limiting (limits for authenticated/unauthenticated, headers, rate limit exceeded response with retry-after), CORS (allowed origins, headers), webhooks (registering, payload format, security with signature verification), idempotency (idempotent requests with idempotency-key header), caching (cache headers for different scenarios, conditional requests with ETag), API documentation (OpenAPI/Swagger spec and interactive docs links), API endpoints reference (tables by resource showing method/endpoint/description), testing (tools, example requests with curl), changelog (current version and future versions), and best practices summary. Critical for maintaining API consistency that AI agents follow during API development.

---

## Key Concepts

**llms.txt Optimization Framework**: The LLM_TXT_STANDARDS.md defines a research-backed approach where "RAG with full documents as retrieval units" enables LLMs to reason about which files to read based on clear descriptions. Optimized descriptions must explain WHEN to read a file (use cases), WHAT you'll learn (specific concepts with function/class names), and WHY it matters (dependencies and relationships). This achieves 95% success rate vs 85% for vector databases or 70% for context stuffing.

**AI-Native Development Template Kit**: The cursor/, prompts/, and project-templates/ folders work together to establish AI-native development practices. cursor/rules.md controls AI agent behavior (plan first, small changes, test-first). The six prompts/ files provide copy-paste workflows for common tasks (planning, debugging, feature development, testing, refactoring, PR writing). The ten project-templates/ files create persistent project memory for AI agents (llms.txt for navigation, memory.md for history, architecture.md for design, decisions.md for rationale, plus standards for testing/coding/deployment/APIs and planning docs like roadmap.md/tasks.md). Together they reduce hallucinations and improve AI coding assistant performance by providing clear context and behavioral expectations.

**Client Retainer Structure**: The three client-docs templates work together to establish and maintain retainer relationships. RETAINER_AGREEMENT.template.md defines the legal and operational framework (hours, SLA, scope). RETAINER_VALUE_ANALYSIS.template.md provides the financial justification and positioning strategy to win the client. MONTHLY_REPORT.template.md demonstrates ongoing value and maintains transparency. Together they support transitioning from unpredictable project work to recurring revenue with 20-40 hour monthly engagements.

**ML Runbook Hierarchy**: The oncall-runbooks follow a two-tier documentation pattern. The short version (ml_oncall_runbooks_master_short.md) serves as triage and orientation, helping oncall engineers quickly identify incident category. The master version (ml_oncall_runbooks_master.md) provides detailed procedures for resolution. Both use concrete examples (Iris classifier v1/v2/v3) to make abstract ML concepts tangible.

**Template Repository Philosophy**: All templates follow a fill-in-the-blank approach with [PLACEHOLDER] syntax making it obvious where customization is needed. They balance comprehensiveness (covering edge cases and details) with usability (clear sections, searchable structure). Templates are designed for direct use, not as examples requiring significant adaptation. Copy templates into new projects and customize for project-specific needs rather than referencing them externally.

---

## Common Tasks

**To set up a new project with AI-native templates**: Copy cursor/rules.md to .cursor/rules.md in the project root. Copy all files from project-templates/ to project root. Fill in placeholders marked with [BRACKETS] in each template file. Start with llms.txt, memory.md, and architecture.md as highest priority. Use prompts/ folder files by referencing them with @ in Cursor (e.g., @prompts/planning.md) or copy-paste as needed during development.

**To create an llms.txt file for a new project**: Reference the LLM_TXT_STANDARDS.md file and use the command pattern shown in CREATE_LLM_TXT.md. Either auto-generate by having an AI scan all files and create descriptions following the standards, or manually fill in llms.txt.template with project-specific details. Optimize descriptions to explain when/what/why for each file.

**To use the development prompts effectively**: Reference prompts using @ syntax in Cursor before starting work. Use @prompts/planning.md before implementing features to create a plan first. Use @prompts/debugging.md when investigating bugs to follow systematic debugging. Use @prompts/feature-dev.md for test-first feature development. Use @prompts/testing.md when adding tests. Use @prompts/refactoring.md before restructuring code. Use @prompts/pr-writing.md when creating pull requests. The prompts guide AI agents through best-practice workflows for each task type.

**To prepare a monthly client report**: Copy MONTHLY_REPORT.template.md to a new file with naming pattern like "2025-10-ClientName-Monthly-Report.md". Fill in all bracketed placeholders starting with executive summary (hours used/remaining, key accomplishments), then detailed time logs, work completed by category, system metrics if applicable, costs, and upcoming work. Deliver by the agreed date each month (typically 1st-5th of following month).

**To pitch a retainer agreement**: Start with RETAINER_VALUE_ANALYSIS.template.md to calculate the financial model and prepare your positioning. Use the "What You Say to [Client Contact]" script to frame the proposal. Present RETAINER_AGREEMENT.template.md as the formal contract after verbal agreement. Emphasize predictability for client (fixed costs) and immediate value (first project included saves money vs standalone pricing).

**To handle an ML production incident**: First reference oncall-runbooks/ml_oncall_runbooks_master_short.md to identify which of the 8 runbook categories matches your incident (deployment, monitoring, data pipeline, scaling, data quality, access, or communication). Then open the corresponding section in ml_oncall_runbooks_master.md for detailed diagnostic steps, commands, and rollback procedures.

**To maintain llms.txt files**: Update whenever you add new files, refactor architecture, or add major features. Use the optimization checklist in LLM_TXT_STANDARDS.md to audit quality. Test by asking an AI to solve a task using only your llms.txt and observe if it retrieves the right files. Common maintenance triggers include adding 5+ new files, changing file organization, or updating function signatures referenced in descriptions.

---

## File Organization

```
templates/
├── cursor/                    # Cursor AI behavioral rules
│   └── rules.md              # Copy to .cursor/rules.md in projects
├── prompts/                   # Reusable development prompts
│   ├── planning.md           # Feature planning workflow
│   ├── debugging.md          # Systematic debugging
│   ├── feature-dev.md        # Test-first feature development
│   ├── testing.md            # Comprehensive testing
│   ├── refactoring.md        # Safe refactoring process
│   └── pr-writing.md         # Pull request documentation
├── project-templates/         # Project memory and documentation templates
│   ├── llms.txt              # AI-readable project map template
│   ├── memory.md             # Implementation history template
│   ├── architecture.md       # System architecture template
│   ├── decisions.md          # Architecture Decision Records template
│   ├── roadmap.md            # Product roadmap template
│   ├── tasks.md              # Sprint and task tracking template
│   ├── testing.md            # Testing standards template
│   ├── coding-standards.md   # Code conventions template
│   ├── deployment.md         # Deployment processes template
│   └── api-contracts.md      # API design standards template
├── client-docs/               # Client relationship templates
│   ├── MONTHLY_REPORT.template.md
│   ├── RETAINER_AGREEMENT.template.md
│   └── RETAINER_VALUE_ANALYSIS.template.md
├── llms-txt/                   # llms.txt creation framework
│   ├── LLM_TXT_STANDARDS.md  # Best practices and standards
│   ├── CREATE_LLM_TXT.md     # Quick creation guide
│   ├── llms.txt.template     # Blank structural template
│   ├── prompt.txt            # Single-line creation command
│   └── QUICK_REFERENCE.md    # Command cheatsheet
├── oncall-runbooks/           # ML operations runbooks
│   ├── ml_oncall_runbooks_master.md
│   └── ml_oncall_runbooks_master_short.md
├── README.md                  # Repository overview and usage guide
├── llms.txt                   # This file - repository documentation map
└── AI_REPO_CONTEXT.md        # Context for generating this template repository
```

---

**Last Updated**: February 14, 2026
**Repository Status**: Active template collection
**Usage**: Copy templates to new projects and customize placeholders


